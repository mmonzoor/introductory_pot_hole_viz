{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Tutorial on Visualizing Reported Pot Holes in Toronto\n",
    "\n",
    "In this tutorial, I am covering an introductory tutorial on data mining and data exploration. I am a Data Scientist currently working in Canada's Payments industry. The amount of work needed to gather data for analytics and research always varies on the task at hand. For example, if you are looking at payment processes involving user transactions and you are the company providing the payment service, you may not need to mine your raw data from an external source. If you are working on your own projects or writing up tutorials like I am, it is the easiest to start off with publicly available data. \n",
    "\n",
    "For this tutorial, I will be using [open data](https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/#e2634d40-0dbf-4d91-12fa-83f039307e93) provided by 311 Toronto. This API contains information about reported pot holes by residents in the city of Toronto. This winter we have had some deep freeze followed by warm days which are known to give rise to new pot holes. I am interested to see what areas of the city has been reported to have a high concentration of pot holes. I am also interested to see the workload this puts on the city in terms of the number of days to investigate reported pot holes. Once the reports are investigated, it is also interesting to investigate how long the expected time of repair would be. To complete our objectives, I will take you through a step-by-step guide on data mining, data cleaning, and visualization.\n",
    "\n",
    "### Things you need:\n",
    "1. Python (I am using Python 3.6.6)\n",
    "2. pip (in order to install necessary packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Install and Import Modules that We need. \n",
    "- requests package is used to make API requests from 311 Toronto. We are using \"GET\" method. If you are new to REST and gathering data by making requests to APIs, I suggest you take a read through [this](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Client-side_web_APIs/Introduction).\n",
    "- json package is used take the response sent back to use from our request to 311 Toronto API and put it into a JSON format. JSON stands for JavaScript Object Notation and with this package we can parse and manipulate json objects.\n",
    "- Python's datatime library is very useful and not just for data science projects. Dates appear often and require extensive manipulation. In this tutorial, we define date ranges for the API request that we are making. Convering string dates to datetime objects require the use of this package. \n",
    "- Pandas has been the most important tool I have used in majority of my data science projects and it is one of the most useful libraries in Python to get familiar with if you are going to continue on this path of data science / data analytics. \n",
    "- mplleaflet is the visualization library we are going to use to display our data. It uses matplotlib and leaflet to display longitudes and latitudes on a map object. For more information, take look [here](https://github.com/jwass/mplleaflet). \n",
    "\n",
    "#### Installing Modules and their corresponding versions\n",
    "\n",
    "With pip install the following or use the requirements.txt posted in the github for this project.\n",
    "\n",
    "    - pandas (I am using version 0.24.1)\n",
    "    - matplotlib ( I am using version 3.0.2)\n",
    "    - mplleaflet  \n",
    "\n",
    "If you are using Linux, you can run the commands below from my jupyter notebook with this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install mplleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mplleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deciding on a date range\n",
    "\n",
    "We know that pot holes are problematic during the season of freezing and thawing around late winter and spring. Knowing this, it would be interesting to look at data from this winter because we have had some alternating cold days and warm days. We have defined our date parameters below but feel free to grab this notebook from my Github and change the dates around for more insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "parameter"
    ]
   },
   "outputs": [],
   "source": [
    "# date range parameters\n",
    "start_date = \"2018-11-01 00:00:00\"\n",
    "end_date = \"2019-03-04 00:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.Finness those Dates to Datetime\n",
    "We have defined our variables as strings. Now, we are going to utilize the datetime module and convert the strings into datetime objects. The other thing to note is that according to the 311 Toronto API Readme, dates are accepted only when they are compliant to w3 isoformat. I had some issues achieving this with the datetime.isoformat() and utilized a little hack to add the 'Z' at the end. If you have a better suggestion, please let me know! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def time(input):\n",
    "    if type(input) != datetime.datetime:\n",
    "        dt = datetime.datetime.strptime(input, '%Y-%m-%d %H:%M:%S')\n",
    "        d = dt.isoformat() + 'Z'\n",
    "        return d\n",
    "    elif type(input) == datetime.datetime:\n",
    "        d = input.isoformat() + 'Z'\n",
    "    else: \n",
    "        raise Exception('Please pass properly formatted datetime parameter. E.g.\"2018-10-01 10:01:30\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Understanding the imposed API Limit (1000 records)\n",
    "\n",
    "The 311 Toronto API has a limit of 1000 records in its response object. Having a size limit or a rate limit when working with APIs is more common than you may think. This is a way of ensuring that the servers are not overloaded trying to fulfill a bunch of requests and can provide a good quality of service. We have requested only 3 months of data for our date range above. I have checked to see the average number of recorded pot holes on average per month is usually around 1k and matches the imposed limit. We are going to take our date range and partition it into 30 day periods. This way we can make synchronous requests for each of the 30 day chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def data_partitions(start, end):\n",
    "    '''dealing with the 1k api limit'''\n",
    "    if type(start) != datetime.datetime:\n",
    "        start_date = datetime.datetime.strptime(start, '%Y-%m-%d %H:%M:%S')\n",
    "    if type(end) != datetime.datetime:\n",
    "        end_date = datetime.datetime.strptime(end, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    days_total = end_date - start_date\n",
    "    print(days_total)\n",
    "    if days_total.days > 30:\n",
    "        new_end_dates = [start_date]\n",
    "        rounds = days_total.days // 30\n",
    "        for i in range(rounds):\n",
    "            new_end_dates.append(new_end_dates[-1] + datetime.timedelta(days=29))\n",
    "            new_end_dates.append(new_end_dates[-1] + datetime.timedelta(days=1))\n",
    "        if new_end_dates[-1] != end_date:\n",
    "            new_end_dates.append(end_date)\n",
    "        else:\n",
    "            end_date = end_date + datetime.timedelta(hours=23)\n",
    "            new_end_dates.append(end_date)\n",
    "        return new_end_dates\n",
    "    else:\n",
    "        return [start_date, end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 days, 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2018, 11, 1, 0, 0),\n",
       " datetime.datetime(2018, 11, 30, 0, 0),\n",
       " datetime.datetime(2018, 12, 1, 0, 0),\n",
       " datetime.datetime(2018, 12, 30, 0, 0),\n",
       " datetime.datetime(2018, 12, 31, 0, 0),\n",
       " datetime.datetime(2019, 1, 29, 0, 0),\n",
       " datetime.datetime(2019, 1, 30, 0, 0),\n",
       " datetime.datetime(2019, 2, 28, 0, 0),\n",
       " datetime.datetime(2019, 3, 1, 0, 0),\n",
       " datetime.datetime(2019, 3, 4, 0, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = data_partitions(start_date, end_date)\n",
    "partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above, we are going to take the partitions and get a bunch of start and end ranges. Since we do not want overlapping days pulling the same data, we made sure to add construct our partitions this way. Meaning, we want the first chunk of days to be from 2018-01-01 to 2018-01-30. The next chunk we want to **make sure** starts from 2018-01-31 instead of 2018-01-30. Using this odd / even relationship of the list above we will construct our ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# take every even numbers\n",
    "start_ranges = partitions[::2]\n",
    "# take every odd numbers\n",
    "end_ranges = partitions[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fetch the Actual Data\n",
    "\n",
    "It is time to make the actual api request to 311 Toronto. In our base url we have some parameters like the service_code=CSROWR-12 and this specifies we only want data for reported pot holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clob = []\n",
    "def data(start_range, end_range):\n",
    "    sd = start_range.isoformat() + 'Z'\n",
    "    ed = end_range.isoformat() + 'Z'\n",
    "    base_url = \"https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&\"\n",
    "    url = base_url+'start_date'+'='+sd+'&'+'end_date'+'='+ed\n",
    "    print(url)\n",
    "    return requests.get(url).json()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-11-01T00:00:00Z&end_date=2018-11-30T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-12-01T00:00:00Z&end_date=2018-12-30T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-12-31T00:00:00Z&end_date=2019-01-29T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2019-01-30T00:00:00Z&end_date=2019-02-28T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2019-03-01T00:00:00Z&end_date=2019-03-04T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(start_ranges):\n",
    "    data_clob.append(data(start_ranges[i], end_ranges[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Clean the Data\n",
    "\n",
    "We know we have a giant list of responses from the get requests we made earlier. Let's take a quick look at what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below to print the result of the first pull\n",
    "#data_clob[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only pulled the first data_clob item and we see that it is a nested JSON containing records of service requests on reported pot holes. We know that the values we are interested in is the list object that is paired to the key \"service_requests\" as shown above. We are going to iterate through every data clob object and pull this list out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# data clob is a nested dictionary always starting with the key 'service_requests' -- clean and get only the values for this.\n",
    "data_set = []\n",
    "for result in data_clob:\n",
    "    data = result['service_requests']\n",
    "    data_set.append(data)\n",
    "\n",
    "# combine partitioned lists into a single list object\n",
    "data_set = sum(data_set, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Construct Base DataFrame\n",
    "\n",
    "This is where the magic of Pandas come into play. Pandas can read your data from a bunch of formats like csv, dictionary, lists and put it into a data frame for you. I frequently use pandas with this handy tool called sqlalchemy to connect to databases and pandas has a way to also read sql. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_id</th>\n",
       "      <th>agency_responsible</th>\n",
       "      <th>description</th>\n",
       "      <th>expected_datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>media_url</th>\n",
       "      <th>requested_datetime</th>\n",
       "      <th>service_code</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_notice</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_notes</th>\n",
       "      <th>updated_datetime</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Wyndcliff Cres, North York, Ward: Don Valley...</td>\n",
       "      <td>577825.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-11-29T17:01:00-05:00</td>\n",
       "      <td>43.735401</td>\n",
       "      <td>-79.317378</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-29T17:01:00-05:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005623750</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-30T14:02:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2455 Eglinton Ave E, , Scarborough, Ward: Scar...</td>\n",
       "      <td>6674325.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-02-27T16:04:00-05:00</td>\n",
       "      <td>43.731228</td>\n",
       "      <td>-79.267562</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-29T16:04:00-05:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005623708</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-12-06T07:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>776 Cummer Ave, North York, Ward: Willowdale (...</td>\n",
       "      <td>504954.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-12-03T15:01:00-05:00</td>\n",
       "      <td>43.798456</td>\n",
       "      <td>-79.378222</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-29T15:01:00-05:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005623487</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-12-03T05:05:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steeles Ave E / Kennedy Rd, Scarborough</td>\n",
       "      <td>13441814.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-02-27T15:00:00-05:00</td>\n",
       "      <td>43.823699</td>\n",
       "      <td>-79.307070</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-29T15:00:00-05:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005623421</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-12-03T06:03:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225 Carmichael Ave, North York, Ward: Eglinton...</td>\n",
       "      <td>7110988.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-12-03T15:00:00-05:00</td>\n",
       "      <td>43.734946</td>\n",
       "      <td>-79.431270</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-29T15:00:00-05:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005623420</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-12-03T12:05:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address  address_id  \\\n",
       "0  2 Wyndcliff Cres, North York, Ward: Don Valley...    577825.0   \n",
       "1  2455 Eglinton Ave E, , Scarborough, Ward: Scar...   6674325.0   \n",
       "2  776 Cummer Ave, North York, Ward: Willowdale (...    504954.0   \n",
       "3            Steeles Ave E / Kennedy Rd, Scarborough  13441814.0   \n",
       "4  225 Carmichael Ave, North York, Ward: Eglinton...   7110988.0   \n",
       "\n",
       "  agency_responsible description          expected_datetime        lat  \\\n",
       "0        311 Toronto        None  2022-11-29T17:01:00-05:00  43.735401   \n",
       "1        311 Toronto        None  2019-02-27T16:04:00-05:00  43.731228   \n",
       "2        311 Toronto        None  2018-12-03T15:01:00-05:00  43.798456   \n",
       "3        311 Toronto        None  2019-02-27T15:00:00-05:00  43.823699   \n",
       "4        311 Toronto        None  2018-12-03T15:00:00-05:00  43.734946   \n",
       "\n",
       "        long media_url         requested_datetime service_code  \\\n",
       "0 -79.317378      None  2018-11-29T17:01:00-05:00    CSROWR-12   \n",
       "1 -79.267562      None  2018-11-29T16:04:00-05:00    CSROWR-12   \n",
       "2 -79.378222      None  2018-11-29T15:01:00-05:00    CSROWR-12   \n",
       "3 -79.307070      None  2018-11-29T15:00:00-05:00    CSROWR-12   \n",
       "4 -79.431270      None  2018-11-29T15:00:00-05:00    CSROWR-12   \n",
       "\n",
       "      service_name service_notice  service_request_id  status  \\\n",
       "0  Road - Pot hole           None        101005623750  closed   \n",
       "1  Road - Pot hole           None        101005623708  closed   \n",
       "2  Road - Pot hole           None        101005623487  closed   \n",
       "3  Road - Pot hole           None        101005623421  closed   \n",
       "4  Road - Pot hole           None        101005623420  closed   \n",
       "\n",
       "                                  status_notes           updated_datetime  \\\n",
       "0  Completed - The request has been concluded.  2018-11-30T14:02:00-05:00   \n",
       "1  Completed - The request has been concluded.  2018-12-06T07:00:00-05:00   \n",
       "2  Completed - The request has been concluded.  2018-12-03T05:05:00-05:00   \n",
       "3  Completed - The request has been concluded.  2018-12-03T06:03:00-05:00   \n",
       "4  Completed - The request has been concluded.  2018-12-03T12:05:00-05:00   \n",
       "\n",
       "  zipcode  \n",
       "0    None  \n",
       "1    None  \n",
       "2    None  \n",
       "3    None  \n",
       "4    None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.DataFrame.from_dict(data_set)\n",
    "# head() shows you first five rows but you can see more by running an int parameter like df_raw.head(10)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7. Data Post-Processing\n",
    "From the readme doc posted by 311 Toronto we know the following:\n",
    "- agency_responsible always set to 311 Toronto\n",
    "- service_notice: not returned\n",
    "- zipcode: not returned \n",
    "\n",
    "Based on this information, we will clean up the dataframe by dropping the corresponding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days = df_raw.drop(['agency_responsible', 'service_notice', 'zipcode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8. Actual Calculations\n",
    "\n",
    "##### Calculate Difference in Days between Updated Case Date and Expected Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days['requested_datetime'] = pd.to_datetime(df_raw.requested_datetime, utc=True)\n",
    "df_delta_days['updated_datetime'] = pd.to_datetime(df_raw.updated_datetime, utc=True)\n",
    "df_delta_days['expected_datetime'] = pd.to_datetime(df_raw.expected_datetime, utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 9. How long does the city take to respond and investigate?\n",
    "Since the days from the request_date and the updated_datetime indicate the investigation period, this would be an interesting parameter to also calculate. We will call this investigation_days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days['investigation_days'] = df_delta_days.updated_datetime - df_delta_days.requested_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days['repair_days'] = df_delta_days.expected_datetime.values.astype('datetime64[D]') - df_delta_days.updated_datetime.values.astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Further cleaning - drop nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days = df_delta_days.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_id</th>\n",
       "      <th>description</th>\n",
       "      <th>expected_datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>media_url</th>\n",
       "      <th>requested_datetime</th>\n",
       "      <th>service_code</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_notes</th>\n",
       "      <th>updated_datetime</th>\n",
       "      <th>investigation_days</th>\n",
       "      <th>repair_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1883 McNicoll Ave, Scarborough, Ward: Scarboro...</td>\n",
       "      <td>9668413.0</td>\n",
       "      <td>64m w. of Kennedy measured by pedometer on the...</td>\n",
       "      <td>2018-12-03 17:01:00+00:00</td>\n",
       "      <td>43.811540</td>\n",
       "      <td>-79.302262</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0120...</td>\n",
       "      <td>2018-11-29 17:01:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005622995</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-29 18:02:00+00:00</td>\n",
       "      <td>0 days 01:01:00</td>\n",
       "      <td>4 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>63 McCool Crt, Scarborough, Ward: Scarborough-...</td>\n",
       "      <td>5024145.0</td>\n",
       "      <td>275m n. of McNicoll Ave. measured by pedometer...</td>\n",
       "      <td>2018-12-03 16:02:00+00:00</td>\n",
       "      <td>43.818150</td>\n",
       "      <td>-79.283483</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0120...</td>\n",
       "      <td>2018-11-29 16:02:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005622805</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-29 18:03:00+00:00</td>\n",
       "      <td>0 days 02:01:00</td>\n",
       "      <td>4 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1755 Brimley Rd, Scarborough, Loblaws, Ward: S...</td>\n",
       "      <td>20081688.0</td>\n",
       "      <td>S. end of bridge over Hwy. 401, 104m and 92m m...</td>\n",
       "      <td>2018-12-03 15:02:00+00:00</td>\n",
       "      <td>43.778160</td>\n",
       "      <td>-79.263321</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0120...</td>\n",
       "      <td>2018-11-29 15:02:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005622651</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-30 18:05:00+00:00</td>\n",
       "      <td>1 days 03:03:00</td>\n",
       "      <td>3 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3555 Danforth Ave, Scarborough, Chester Villag...</td>\n",
       "      <td>20063025.0</td>\n",
       "      <td>105m w. of Warden Ave. measured by pedometer, ...</td>\n",
       "      <td>2022-11-29 13:03:00+00:00</td>\n",
       "      <td>43.693787</td>\n",
       "      <td>-79.274737</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0120...</td>\n",
       "      <td>2018-11-29 13:03:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005622366</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-30 18:03:00+00:00</td>\n",
       "      <td>1 days 05:00:00</td>\n",
       "      <td>1460 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1025 Lake Shore Blvd E, former Toronto, Ward: ...</td>\n",
       "      <td>20154275.0</td>\n",
       "      <td>This is DANGEROUS.  Broken concrete around str...</td>\n",
       "      <td>2022-11-28 19:01:00+00:00</td>\n",
       "      <td>43.658356</td>\n",
       "      <td>-79.328929</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0118...</td>\n",
       "      <td>2018-11-28 19:01:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005621507</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-12-05 14:05:00+00:00</td>\n",
       "      <td>6 days 19:04:00</td>\n",
       "      <td>1454 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              address  address_id  \\\n",
       "22  1883 McNicoll Ave, Scarborough, Ward: Scarboro...   9668413.0   \n",
       "27  63 McCool Crt, Scarborough, Ward: Scarborough-...   5024145.0   \n",
       "31  1755 Brimley Rd, Scarborough, Loblaws, Ward: S...  20081688.0   \n",
       "37  3555 Danforth Ave, Scarborough, Chester Villag...  20063025.0   \n",
       "57  1025 Lake Shore Blvd E, former Toronto, Ward: ...  20154275.0   \n",
       "\n",
       "                                          description  \\\n",
       "22  64m w. of Kennedy measured by pedometer on the...   \n",
       "27  275m n. of McNicoll Ave. measured by pedometer...   \n",
       "31  S. end of bridge over Hwy. 401, 104m and 92m m...   \n",
       "37  105m w. of Warden Ave. measured by pedometer, ...   \n",
       "57  This is DANGEROUS.  Broken concrete around str...   \n",
       "\n",
       "           expected_datetime        lat       long  \\\n",
       "22 2018-12-03 17:01:00+00:00  43.811540 -79.302262   \n",
       "27 2018-12-03 16:02:00+00:00  43.818150 -79.283483   \n",
       "31 2018-12-03 15:02:00+00:00  43.778160 -79.263321   \n",
       "37 2022-11-29 13:03:00+00:00  43.693787 -79.274737   \n",
       "57 2022-11-28 19:01:00+00:00  43.658356 -79.328929   \n",
       "\n",
       "                                            media_url  \\\n",
       "22  http://seeclickfix.com/files/issue_images/0120...   \n",
       "27  http://seeclickfix.com/files/issue_images/0120...   \n",
       "31  http://seeclickfix.com/files/issue_images/0120...   \n",
       "37  http://seeclickfix.com/files/issue_images/0120...   \n",
       "57  http://seeclickfix.com/files/issue_images/0118...   \n",
       "\n",
       "          requested_datetime service_code     service_name  \\\n",
       "22 2018-11-29 17:01:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "27 2018-11-29 16:02:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "31 2018-11-29 15:02:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "37 2018-11-29 13:03:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "57 2018-11-28 19:01:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "\n",
       "    service_request_id  status                                 status_notes  \\\n",
       "22        101005622995  closed  Completed - The request has been concluded.   \n",
       "27        101005622805  closed  Completed - The request has been concluded.   \n",
       "31        101005622651  closed  Completed - The request has been concluded.   \n",
       "37        101005622366  closed  Completed - The request has been concluded.   \n",
       "57        101005621507  closed  Completed - The request has been concluded.   \n",
       "\n",
       "            updated_datetime investigation_days repair_days  \n",
       "22 2018-11-29 18:02:00+00:00    0 days 01:01:00      4 days  \n",
       "27 2018-11-29 18:03:00+00:00    0 days 02:01:00      4 days  \n",
       "31 2018-11-30 18:05:00+00:00    1 days 03:03:00      3 days  \n",
       "37 2018-11-30 18:03:00+00:00    1 days 05:00:00   1460 days  \n",
       "57 2018-12-05 14:05:00+00:00    6 days 19:04:00   1454 days  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delta_days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of total records\n",
    "df_delta_days.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice is that we see records that have over 1400 days for expected repair. This might be because it is an auto-populated that gets filled under certain conditions and then re-updated at a later date. We can't be sure since it is not our data but it is something to keep in mind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 10.Visualization Investigation\n",
    "\n",
    "We want to know what the average days of investigation and repairs are. Based on this, we want to create a threshold. Any record that took less than or equal to the average time to investigate we are going to assume were fast investigations. We are going to follow a similar logic for the repair days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load longitude, latitude data\n",
    "# slow investigations\n",
    "mean_days = (df_delta_days['investigation_days'].values).mean()\n",
    "slow_long = df_delta_days[df_delta_days.investigation_days.values > mean_days].long\n",
    "slow_lat = df_delta_days[df_delta_days.investigation_days > mean_days].lat\n",
    "\n",
    "#quick investigations\n",
    "fast_long = df_delta_days[df_delta_days.investigation_days.values <= mean_days].long\n",
    "fast_lat = df_delta_days[df_delta_days['investigation_days'] <= mean_days].lat\n",
    "\n",
    "# slow repairs\n",
    "mean_repairs = (df_delta_days['repair_days'].values).mean()\n",
    "slow_long_r = df_delta_days[df_delta_days.repair_days.values > mean_repairs].long\n",
    "slow_lat_r = df_delta_days[df_delta_days.repair_days.values > mean_repairs].lat\n",
    "\n",
    "#quick repairs\n",
    "fast_long_r = df_delta_days[df_delta_days.repair_days.values <= mean_repairs].long\n",
    "fast_lat_r = df_delta_days[df_delta_days.repair_days.values <= mean_repairs].lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot our findings above on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on plotlib\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "plt.plot(slow_long_r, slow_lat_r, 'rs') # slow repair\n",
    "plt.plot(fast_long_r, fast_lat_r, 'gs') # fast repair\n",
    "plt.plot(slow_long, slow_lat, 'b.') # slow investigation\n",
    "plt.plot(fast_long, fast_lat, 'k.') # fast investigation\n",
    "# display mplleaflet within notebook\n",
    "#mplleaflet.display()\n",
    "\n",
    "mplleaflet.show(path='pot_holes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Visualization\n",
    "We see slow repairs for the areas near downtown core. We see that the city is fast at investigating reports in the NW side of the city. \n",
    "\n",
    "The scope of this tutorial was to cover the steps to gathering and preparing data ready for analysis. We did not delve into the analysis portion much in this tutorial but unexplored columns in our Pandas raw dataframe are now cleaned and available for your to explore on your own. Some interesting tips would be to look at submitted photos of the pot holes in the reports (under medua_url column). Image analysis is a fascinating area of data science with many open source projects in the area to get involved with. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311_api",
   "language": "python",
   "name": "311_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
