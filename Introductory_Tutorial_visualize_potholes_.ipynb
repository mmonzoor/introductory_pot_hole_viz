{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Tutorial on Visualizing Reported Pot Holes in Toronto\n",
    "\n",
    "In this tutorial, I am covering an introductory tutorial on data mining and data exploration. I am a Data Scientist currently working in Canada's Payments industry. The amount of work needed to gather data for analytics and research always varies on the task at hand. For example, if you are looking at payment processes involving user transactions and you are the company providing the payment service, you may not need to mine your raw data from an external source. If you are working on your own projects or writing up tutorials like I am, it is the easiest to start off with publicly available data. \n",
    "\n",
    "For this tutorial, I will be using [open data](https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/#e2634d40-0dbf-4d91-12fa-83f039307e93) provided by 311 Toronto. This API contains information about reported pot holes by residents in the city of Toronto. This winter we have had some deep freeze followed by warm days which are known to give rise to new pot holes. I am interested to see what areas of the city has been reported to have a high concentration of pot holes. I am also interested to see the workload this puts on the city in terms of the number of days to investigate reported pot holes. Once the reports are investigated, it is also interesting to investigate how long the expected time of repair would be. To complete our objectives, I will take you through a step-by-step guide on data mining, data cleaning, and visualization.\n",
    "\n",
    "### Things you need:\n",
    "1. Python (I am using Python 3.6.6)\n",
    "2. pip (in order to install necessary packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Install and Import Modules that We need. \n",
    "- requests package is used to make API requests from 311 Toronto. We are using \"GET\" method. If you are new to REST and gathering data by making requests to APIs, I suggest you take a read through [this](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Client-side_web_APIs/Introduction).\n",
    "- json package is used take the response sent back to use from our request to 311 Toronto API and put it into a JSON format. JSON stands for JavaScript Object Notation and with this package we can parse and manipulate json objects.\n",
    "- Python's datatime library is very useful and not just for data science projects. Dates appear often and require extensive manipulation. In this tutorial, we define date ranges for the API request that we are making. Convering string dates to datetime objects require the use of this package. \n",
    "- Pandas has been the most important tool I have used in majority of my data science projects and it is one of the most useful libraries in Python to get familiar with if you are going to continue on this path of data science / data analytics. \n",
    "- mplleaflet is the visualization library we are going to use to display our data. It uses matplotlib and leaflet to display longitudes and latitudes on a map object. For more information, take look [here](https://github.com/jwass/mplleaflet). \n",
    "\n",
    "#### Installing Modules and their corresponding versions\n",
    "\n",
    "With pip install the following or use the requirements.txt posted in the github for this project.\n",
    "\n",
    "    - pandas (I am using version 0.24.1)\n",
    "    - matplotlib ( I am using version 3.0.2)\n",
    "    - mplleaflet  \n",
    "\n",
    "If you are using Linux, you can run the commands below from my jupyter notebook with this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install mplleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mplleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deciding on a date range\n",
    "\n",
    "We know that pot holes are problematic during the season of freezing and thawing around late winter and spring. Knowing this, it would be interesting to look at data from this winter because we have had some alternating cold days and warm days. We have defined our date parameters below but feel free to grab this notebook from my Github and change the dates around for more insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "parameter"
    ]
   },
   "outputs": [],
   "source": [
    "# date range parameters\n",
    "start_date = \"2018-10-01 00:00:00\"\n",
    "end_date = \"2019-02-16 00:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.Finness those Dates to Datetime\n",
    "We have defined our variables as strings. Now, we are going to utilize the datetime module and convert the strings into datetime objects. The other thing to note is that according to the 311 Toronto API Readme, dates are accepted only when they are compliant to w3 isoformat. I had some issues achieving this with the datetime.isoformat() and utilized a little hack to add the 'Z' at the end. If you have a better suggestion, please let me know! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def time(input):\n",
    "    if type(input) != datetime.datetime:\n",
    "        dt = datetime.datetime.strptime(input, '%Y-%m-%d %H:%M:%S')\n",
    "        d = dt.isoformat() + 'Z'\n",
    "        return d\n",
    "    elif type(input) == datetime.datetime:\n",
    "        d = input.isoformat() + 'Z'\n",
    "    else: \n",
    "        raise Exception('Please pass properly formatted datetime parameter. E.g.\"2018-10-01 10:01:30\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Understanding the imposed API Limit (1000 records)\n",
    "\n",
    "The 311 Toronto API has a limit of 1000 records in its response object. Having a size limit or a rate limit when working with APIs is more common than you may think. This is a way of ensuring that the servers are not overloaded trying to fulfill a bunch of requests and can provide a good quality of service. We have requested only 3 months of data for our date range above. I have checked to see the average number of recorded pot holes on average per month is usually around 1k and matches the imposed limit. We are going to take our date range and partition it into 30 day periods. This way we can make synchronous requests for each of the 30 day chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def data_partitions(start, end):\n",
    "    '''dealing with the 1k api limit'''\n",
    "    if type(start) != datetime.datetime:\n",
    "        start_date = datetime.datetime.strptime(start, '%Y-%m-%d %H:%M:%S')\n",
    "    if type(end) != datetime.datetime:\n",
    "        end_date = datetime.datetime.strptime(end, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    days_total = end_date - start_date\n",
    "    print(days_total)\n",
    "    if days_total.days > 30:\n",
    "        new_end_dates = [start_date]\n",
    "        rounds = days_total.days // 30\n",
    "        for i in range(rounds):\n",
    "            new_end_dates.append(new_end_dates[-1] + datetime.timedelta(days=29))\n",
    "            new_end_dates.append(new_end_dates[-1] + datetime.timedelta(days=1))\n",
    "        if new_end_dates[-1] != end_date:\n",
    "            new_end_dates.append(end_date)\n",
    "        else:\n",
    "            end_date = end_date + datetime.timedelta(hours=23)\n",
    "            new_end_dates.append(end_date)\n",
    "        return new_end_dates\n",
    "    else:\n",
    "        return [start_date, end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 days, 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2018, 10, 1, 0, 0),\n",
       " datetime.datetime(2018, 10, 30, 0, 0),\n",
       " datetime.datetime(2018, 10, 31, 0, 0),\n",
       " datetime.datetime(2018, 11, 29, 0, 0),\n",
       " datetime.datetime(2018, 11, 30, 0, 0),\n",
       " datetime.datetime(2018, 12, 29, 0, 0),\n",
       " datetime.datetime(2018, 12, 30, 0, 0),\n",
       " datetime.datetime(2019, 1, 28, 0, 0),\n",
       " datetime.datetime(2019, 1, 29, 0, 0),\n",
       " datetime.datetime(2019, 2, 16, 0, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = data_partitions(start_date, end_date)\n",
    "partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above, we are going to take the partitions and get a bunch of start and end ranges. Since we do not want overlapping days pulling the same data, we made sure to add construct our partitions this way. Meaning, we want the first chunk of days to be from 2018-01-01 to 2018-01-30. The next chunk we want to **make sure** starts from 2018-01-31 instead of 2018-01-30. Using this odd / even relationship of the list above we will construct our ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# take every even numbers\n",
    "start_ranges = partitions[::2]\n",
    "# take every odd numbers\n",
    "end_ranges = partitions[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fetch the Actual Data\n",
    "\n",
    "It is time to make the actual api request to 311 Toronto. In our base url we have some parameters like the service_code=CSROWR-12 and this specifies we only want data for reported pot holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clob = []\n",
    "def data(start_range, end_range):\n",
    "    sd = start_range.isoformat() + 'Z'\n",
    "    ed = end_range.isoformat() + 'Z'\n",
    "    base_url = \"https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&\"\n",
    "    url = base_url+'start_date'+'='+sd+'&'+'end_date'+'='+ed\n",
    "    print(url)\n",
    "    data = requests.get(url).json()\n",
    "    data_clob.append(data)\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-10-01T00:00:00Z&end_date=2018-10-30T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-10-31T00:00:00Z&end_date=2018-11-29T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-11-30T00:00:00Z&end_date=2018-12-29T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2018-12-30T00:00:00Z&end_date=2019-01-28T00:00:00Z\n",
      "https://secure.toronto.ca/webwizard/ws/requests.json?jurisdiction_id=toronto.ca&service_code=CSROWR-12&start_date=2019-01-29T00:00:00Z&end_date=2019-02-16T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(start_ranges):\n",
    "    data(start_ranges[i], end_ranges[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Clean the Data\n",
    "\n",
    "We know we have a giant list of responses from the get requests we made earlier. Let's take a quick look at what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below to print the result of the first pull\n",
    "#data_clob[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only pulled the first data_clob item and we see that it is a nested JSON containing records of service requests on reported pot holes. We know that the values we are interested in is the list object that is paired to the key \"service_requests\" as shown above. We are going to iterate through every data clob object and pull this list out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# data clob is a nested dictionary always starting with the key 'service_requests' -- clean and get only the values for this.\n",
    "data_set = []\n",
    "for result in data_clob:\n",
    "    data = result['service_requests']\n",
    "    data_set.append(data)\n",
    "\n",
    "# combine partitioned lists into a single list object\n",
    "data_set = sum(data_set, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Construct Base DataFrame\n",
    "\n",
    "This is where the magic of Pandas come into play. Pandas can read your data from a bunch of formats like csv, dictionary, lists and put it into a data frame for you. I frequently use pandas with this handy tool called sqlalchemy to connect to databases and pandas has a way to also read sql. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_id</th>\n",
       "      <th>agency_responsible</th>\n",
       "      <th>description</th>\n",
       "      <th>expected_datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>media_url</th>\n",
       "      <th>requested_datetime</th>\n",
       "      <th>service_code</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_notice</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_notes</th>\n",
       "      <th>updated_datetime</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430 Sheppard Ave W, North York, Sheppard Publ...</td>\n",
       "      <td>10133016.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-04-29T17:03:00-04:00</td>\n",
       "      <td>43.743649</td>\n",
       "      <td>-79.491850</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-29T17:03:00-04:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005572079</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-10-30T13:03:00-04:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rathburn Rd / Melbert Rd, Etobicoke</td>\n",
       "      <td>13467170.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-02T15:04:00-04:00</td>\n",
       "      <td>43.650021</td>\n",
       "      <td>-79.582740</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-29T15:04:00-04:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005571876</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-07T14:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winterton Dr / Lloyd Manor Rd, Etobicoke</td>\n",
       "      <td>13463541.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-02T15:04:00-04:00</td>\n",
       "      <td>43.671929</td>\n",
       "      <td>-79.555053</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-29T15:04:00-04:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005571889</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-07T14:01:00-05:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GARDINER EXPRESS / Lake Shore Blvd E / Booth A...</td>\n",
       "      <td>13466078.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>43.653533</td>\n",
       "      <td>-79.340792</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-29T14:04:00-04:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005571749</td>\n",
       "      <td>closed</td>\n",
       "      <td>Cancelled - The request may be a duplicate, wo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GARDINER EXPRESS / Lake Shore Blvd W, former T...</td>\n",
       "      <td>13468963.0</td>\n",
       "      <td>311 Toronto</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-01-27T14:01:00-05:00</td>\n",
       "      <td>43.633417</td>\n",
       "      <td>-79.435976</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-29T14:01:00-04:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>None</td>\n",
       "      <td>101005571645</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-10-30T11:04:00-04:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address  address_id  \\\n",
       "0  1430 Sheppard Ave W, North York, Sheppard Publ...  10133016.0   \n",
       "1                Rathburn Rd / Melbert Rd, Etobicoke  13467170.0   \n",
       "2           Winterton Dr / Lloyd Manor Rd, Etobicoke  13463541.0   \n",
       "3  GARDINER EXPRESS / Lake Shore Blvd E / Booth A...  13466078.0   \n",
       "4  GARDINER EXPRESS / Lake Shore Blvd W, former T...  13468963.0   \n",
       "\n",
       "  agency_responsible description          expected_datetime        lat  \\\n",
       "0        311 Toronto        None  2020-04-29T17:03:00-04:00  43.743649   \n",
       "1        311 Toronto        None  2018-11-02T15:04:00-04:00  43.650021   \n",
       "2        311 Toronto        None  2018-11-02T15:04:00-04:00  43.671929   \n",
       "3        311 Toronto        None                       None  43.653533   \n",
       "4        311 Toronto        None  2019-01-27T14:01:00-05:00  43.633417   \n",
       "\n",
       "        long media_url         requested_datetime service_code  \\\n",
       "0 -79.491850      None  2018-10-29T17:03:00-04:00    CSROWR-12   \n",
       "1 -79.582740      None  2018-10-29T15:04:00-04:00    CSROWR-12   \n",
       "2 -79.555053      None  2018-10-29T15:04:00-04:00    CSROWR-12   \n",
       "3 -79.340792      None  2018-10-29T14:04:00-04:00    CSROWR-12   \n",
       "4 -79.435976      None  2018-10-29T14:01:00-04:00    CSROWR-12   \n",
       "\n",
       "      service_name service_notice  service_request_id  status  \\\n",
       "0  Road - Pot hole           None        101005572079  closed   \n",
       "1  Road - Pot hole           None        101005571876  closed   \n",
       "2  Road - Pot hole           None        101005571889  closed   \n",
       "3  Road - Pot hole           None        101005571749  closed   \n",
       "4  Road - Pot hole           None        101005571645  closed   \n",
       "\n",
       "                                        status_notes  \\\n",
       "0        Completed - The request has been concluded.   \n",
       "1        Completed - The request has been concluded.   \n",
       "2        Completed - The request has been concluded.   \n",
       "3  Cancelled - The request may be a duplicate, wo...   \n",
       "4        Completed - The request has been concluded.   \n",
       "\n",
       "            updated_datetime zipcode  \n",
       "0  2018-10-30T13:03:00-04:00    None  \n",
       "1  2018-11-07T14:00:00-05:00    None  \n",
       "2  2018-11-07T14:01:00-05:00    None  \n",
       "3                       None    None  \n",
       "4  2018-10-30T11:04:00-04:00    None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.DataFrame.from_dict(data_set)\n",
    "# head() shows you first five rows but you can see more by running an int parameter like df_raw.head(10)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7. Data Post-Processing\n",
    "From the readme doc posted by 311 Toronto we know the following:\n",
    "- agency_responsible always set to 311 Toronto\n",
    "- service_notice: not returned\n",
    "- zipcode: not returned \n",
    "\n",
    "Based on this information, we will clean up the dataframe by dropping the corresponding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days = df_raw.drop(['agency_responsible', 'service_notice', 'zipcode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8. Actual Calculations\n",
    "\n",
    "##### Calculate Difference in Days between Updated Case Date and Expected Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days['requested_datetime'] = pd.to_datetime(df_raw.requested_datetime, utc=True)\n",
    "df_delta_days['updated_datetime'] = pd.to_datetime(df_raw.updated_datetime, utc=True)\n",
    "df_delta_days['expected_datetime'] = pd.to_datetime(df_raw.expected_datetime, utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 9. How long does the city take to respond and investigate?\n",
    "Since the days from the request_date and the updated_datetime indicate the investigation period, this would be an interesting parameter to also calculate. We will call this investigation_days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days['investigation_days'] = df_delta_days.updated_datetime - df_delta_days.requested_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days['repair_days'] = df_delta_days.expected_datetime.values.astype('datetime64[D]') - df_delta_days.updated_datetime.values.astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Further cleaning - drop nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_delta_days = df_delta_days.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_id</th>\n",
       "      <th>description</th>\n",
       "      <th>expected_datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>media_url</th>\n",
       "      <th>requested_datetime</th>\n",
       "      <th>service_code</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_notes</th>\n",
       "      <th>updated_datetime</th>\n",
       "      <th>investigation_days</th>\n",
       "      <th>repair_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5910 Finch Ave E, Scarborough, Ward: Scarborou...</td>\n",
       "      <td>6947314.0</td>\n",
       "      <td>On n. curb 1m e. of e. pedestrian crossing.</td>\n",
       "      <td>2022-10-24 15:04:00+00:00</td>\n",
       "      <td>43.817674</td>\n",
       "      <td>-79.224815</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0117...</td>\n",
       "      <td>2018-10-24 15:04:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005564805</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-10-26 11:05:00+00:00</td>\n",
       "      <td>1 days 20:01:00</td>\n",
       "      <td>1459 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1058 Dufferin St, former Toronto, Ward: Davenp...</td>\n",
       "      <td>10180527.0</td>\n",
       "      <td>Directly in front of the porch of 1058 Dufferi...</td>\n",
       "      <td>2019-01-20 23:02:00+00:00</td>\n",
       "      <td>43.661142</td>\n",
       "      <td>-79.436122</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0117...</td>\n",
       "      <td>2018-10-22 22:02:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005562198</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-10-26 12:03:00+00:00</td>\n",
       "      <td>3 days 14:01:00</td>\n",
       "      <td>86 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>155 McNicoll Ave, North York, Ward: Willowdale...</td>\n",
       "      <td>30033326.0</td>\n",
       "      <td>Patchwork not finished at this spot even thoug...</td>\n",
       "      <td>2018-10-25 18:00:00+00:00</td>\n",
       "      <td>43.798982</td>\n",
       "      <td>-79.358084</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0117...</td>\n",
       "      <td>2018-10-21 18:00:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005560224</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-11-14 11:03:00+00:00</td>\n",
       "      <td>23 days 17:03:00</td>\n",
       "      <td>-20 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>4801 Dufferin St, North York, G. Ross Lord Par...</td>\n",
       "      <td>11714766.0</td>\n",
       "      <td>40m s. of Dolomite on e. curb bordering sewer ...</td>\n",
       "      <td>2019-01-15 17:00:00+00:00</td>\n",
       "      <td>43.778172</td>\n",
       "      <td>-79.468741</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0117...</td>\n",
       "      <td>2018-10-17 16:00:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005554783</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-10-23 19:04:00+00:00</td>\n",
       "      <td>6 days 03:04:00</td>\n",
       "      <td>84 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>4239 Dufferin St, North York, Ward: York Centr...</td>\n",
       "      <td>5336716.0</td>\n",
       "      <td>30m n. of Overbook near e. curb.</td>\n",
       "      <td>2019-01-15 17:00:00+00:00</td>\n",
       "      <td>43.762137</td>\n",
       "      <td>-79.465040</td>\n",
       "      <td>http://seeclickfix.com/files/issue_images/0117...</td>\n",
       "      <td>2018-10-17 16:00:00+00:00</td>\n",
       "      <td>CSROWR-12</td>\n",
       "      <td>Road - Pot hole</td>\n",
       "      <td>101005554751</td>\n",
       "      <td>closed</td>\n",
       "      <td>Completed - The request has been concluded.</td>\n",
       "      <td>2018-10-23 19:04:00+00:00</td>\n",
       "      <td>6 days 03:04:00</td>\n",
       "      <td>84 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               address  address_id  \\\n",
       "93   5910 Finch Ave E, Scarborough, Ward: Scarborou...   6947314.0   \n",
       "136  1058 Dufferin St, former Toronto, Ward: Davenp...  10180527.0   \n",
       "151  155 McNicoll Ave, North York, Ward: Willowdale...  30033326.0   \n",
       "229  4801 Dufferin St, North York, G. Ross Lord Par...  11714766.0   \n",
       "230  4239 Dufferin St, North York, Ward: York Centr...   5336716.0   \n",
       "\n",
       "                                           description  \\\n",
       "93         On n. curb 1m e. of e. pedestrian crossing.   \n",
       "136  Directly in front of the porch of 1058 Dufferi...   \n",
       "151  Patchwork not finished at this spot even thoug...   \n",
       "229  40m s. of Dolomite on e. curb bordering sewer ...   \n",
       "230                   30m n. of Overbook near e. curb.   \n",
       "\n",
       "            expected_datetime        lat       long  \\\n",
       "93  2022-10-24 15:04:00+00:00  43.817674 -79.224815   \n",
       "136 2019-01-20 23:02:00+00:00  43.661142 -79.436122   \n",
       "151 2018-10-25 18:00:00+00:00  43.798982 -79.358084   \n",
       "229 2019-01-15 17:00:00+00:00  43.778172 -79.468741   \n",
       "230 2019-01-15 17:00:00+00:00  43.762137 -79.465040   \n",
       "\n",
       "                                             media_url  \\\n",
       "93   http://seeclickfix.com/files/issue_images/0117...   \n",
       "136  http://seeclickfix.com/files/issue_images/0117...   \n",
       "151  http://seeclickfix.com/files/issue_images/0117...   \n",
       "229  http://seeclickfix.com/files/issue_images/0117...   \n",
       "230  http://seeclickfix.com/files/issue_images/0117...   \n",
       "\n",
       "           requested_datetime service_code     service_name  \\\n",
       "93  2018-10-24 15:04:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "136 2018-10-22 22:02:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "151 2018-10-21 18:00:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "229 2018-10-17 16:00:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "230 2018-10-17 16:00:00+00:00    CSROWR-12  Road - Pot hole   \n",
       "\n",
       "     service_request_id  status                                 status_notes  \\\n",
       "93         101005564805  closed  Completed - The request has been concluded.   \n",
       "136        101005562198  closed  Completed - The request has been concluded.   \n",
       "151        101005560224  closed  Completed - The request has been concluded.   \n",
       "229        101005554783  closed  Completed - The request has been concluded.   \n",
       "230        101005554751  closed  Completed - The request has been concluded.   \n",
       "\n",
       "             updated_datetime investigation_days repair_days  \n",
       "93  2018-10-26 11:05:00+00:00    1 days 20:01:00   1459 days  \n",
       "136 2018-10-26 12:03:00+00:00    3 days 14:01:00     86 days  \n",
       "151 2018-11-14 11:03:00+00:00   23 days 17:03:00    -20 days  \n",
       "229 2018-10-23 19:04:00+00:00    6 days 03:04:00     84 days  \n",
       "230 2018-10-23 19:04:00+00:00    6 days 03:04:00     84 days  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delta_days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of total records\n",
    "df_delta_days.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice is that we see records that have over 1400 days for expected repair. This might be because it is an auto-populated that gets filled under certain conditions and then re-updated at a later date. We can't be sure since it is not our data but it is something to keep in mind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 10.Visualization Investigation\n",
    "\n",
    "We want to know what the average days of investigation and repairs are. Based on this, we want to create a threshold. Any record that took less than or equal to the average time to investigate we are going to assume were fast investigations. We are going to follow a similar logic for the repair days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load longitude, latitude data\n",
    "# slow investigations\n",
    "mean_days = (df_delta_days['investigation_days'].values).mean()\n",
    "slow_long = df_delta_days[df_delta_days.investigation_days.values > mean_days].long\n",
    "slow_lat = df_delta_days[df_delta_days.investigation_days > mean_days].lat\n",
    "\n",
    "#quick investigations\n",
    "fast_long = df_delta_days[df_delta_days.investigation_days.values <= mean_days].long\n",
    "fast_lat = df_delta_days[df_delta_days['investigation_days'] <= mean_days].lat\n",
    "\n",
    "# slow repairs\n",
    "mean_repairs = (df_delta_days['repair_days'].values).mean()\n",
    "slow_long_r = df_delta_days[df_delta_days.repair_days.values > mean_repairs].long\n",
    "slow_lat_r = df_delta_days[df_delta_days.repair_days.values > mean_repairs].lat\n",
    "\n",
    "#quick repairs\n",
    "fast_long_r = df_delta_days[df_delta_days.repair_days.values <= mean_repairs].long\n",
    "fast_lat_r = df_delta_days[df_delta_days.repair_days.values <= mean_repairs].lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot our findings above on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on plotlib\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "plt.plot(slow_long_r, slow_lat_r, 'rs') # slow repair\n",
    "plt.plot(fast_long_r, fast_lat_r, 'gs') # fast repair\n",
    "plt.plot(slow_long, slow_lat, 'b.') # slow investigation\n",
    "plt.plot(fast_long, fast_lat, 'k.') # fast investigation\n",
    "# display mplleaflet within notebook\n",
    "#mplleaflet.display()\n",
    "\n",
    "mplleaflet.show(tiles='cartodb_positron', path='pot_holes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Visualization\n",
    "We see slow repairs for the areas near downtown core. We see that the city is fast at investigating reports in the NW side of the city. \n",
    "\n",
    "The scope of this tutorial was to cover the steps to gathering and preparing data ready for analysis. We did not delve into the analysis portion much in this tutorial but unexplored columns in our Pandas raw dataframe are now cleaned and available for your to explore on your own. Some interesting tips would be to look at submitted photos of the pot holes in the reports (under medua_url column). Image analysis is a fascinating area of data science with many open source projects in the area to get involved with. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311_api",
   "language": "python",
   "name": "311_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
